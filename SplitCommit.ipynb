{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odfHpJlX2PCl"
      },
      "source": [
        "**Installing the Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSrXsKwhlY9W"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.groq import Groq\n",
        "import csv\n",
        "from openai import OpenAI\n",
        "from mistralai import Mistral\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr6WpLKL1lw4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N=1 #can be 1,2,3,4,5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7JrTEFK2qFF"
      },
      "outputs": [],
      "source": [
        "with open(f'sample_200/1k_msg_rawdiff_part_{N}.txt', 'r') as file:\n",
        "    data = file.read()\n",
        "diffs_label = json.loads(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_whitespace_only_diff(diff):\n",
        "    lines = diff.splitlines()\n",
        "    added_pattern = re.compile(r'^\\+')\n",
        "    removed_pattern = re.compile(r'^\\-')\n",
        "    for line in lines:\n",
        "        if added_pattern.match(line) or removed_pattern.match(line):\n",
        "            # Remove the initial '+' or '-' and compare the content ignoring whitespace\n",
        "            content = line[1:].strip()\n",
        "            if content:\n",
        "                return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = list(diffs_label.keys())\n",
        "diffs = list(diffs_label.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_diff_label = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Whitespace Diffs, Bot Commits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HF_TOKEN = 'Hugging_Face_API_Key'\n",
        "pattern = re.compile(r'\\d+ \\. \\d+( \\. \\d+)*')\n",
        "filtered_labels, filtered_diffs = [],[]\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token = HF_TOKEN)\n",
        "for i in range(0,len(labels)):\n",
        "    n_tokens = len(tokenizer.encode(diffs[i]))\n",
        "    if (not pattern.search(labels[i])) and (not is_whitespace_only_diff(diffs[i])) and n_tokens<131072:\n",
        "        filtered_labels.append(labels[i])\n",
        "        filtered_diffs.append(diffs[i])\n",
        "        filtered_diff_label.append({'diff':diffs[i], 'label':labels[i]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(filtered_diff_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgcbkFcl2VSB"
      },
      "outputs": [],
      "source": [
        "groq_api = 'Groq_API_Key'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Groq API for testing with Llama3.1 70B and 8B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4Knje6p69xM"
      },
      "outputs": [],
      "source": [
        "def get_response(model,prompt):\n",
        "  llm_groq = Groq(model=model, api_key=groq_api)\n",
        "  sequences = llm_groq.complete(prompt = prompt)\n",
        "  return sequences.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using OpenAI API for testing with GPT models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY='Open_AI_API_Key'\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "def getGPTResponse(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Mistral API key for Mistral Large model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mistral_key = 'Mistral_API_Key'\n",
        "model = \"mistral-large-2402\"\n",
        "client = Mistral(api_key=mistral_key)\n",
        "def getMistralResponse(prompt):\n",
        "    chat_response = client.chat.complete(\n",
        "        model= model,\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "    return chat_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Full Diff to generate Commit message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cf_1, cf_2, cf_3, cf_4 = [], [], [], []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Llama3.1-70B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cf_1=[]\n",
        "for i in range(0, len(filtered_diff_label)):\n",
        "  if ('llama-70b-output' not in filtered_diff_label[i] or filtered_diff_label[i]['llama-70b-output'] == 'ERROR'):\n",
        "    diff=filtered_diff_label[i]['diff']\n",
        "    prompt = f\"The following is a diff which describes the code changes in a commit, Your task is to write a short commit message accordingly. {diff} According to the diff, the commit message should be:\"\n",
        "    try:\n",
        "      filtered_diff_label[i]['llama-70b-output'] = get_response(\"llama-3.1-70b-versatile\",prompt)\n",
        "    except:\n",
        "      cf_1.append(i)\n",
        "      filtered_diff_label[i]['llama-70b-output'] = 'ERROR'\n",
        "      pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Llama3.1-8B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cf_2=[]\n",
        "for i in range(0, len(filtered_diff_label)):\n",
        "  if ('llama3.1-8b-output' not in filtered_diff_label[i] or filtered_diff_label[i]['llama3.1-8b-output'] == 'ERROR'):\n",
        "    diff=filtered_diff_label[i]['diff']\n",
        "    prompt = f\"The following is a diff which describes the code changes in a commit, Your task is to write a short commit message accordingly. {diff} According to the diff, the commit message should be:\"\n",
        "    try:\n",
        "      filtered_diff_label[i]['llama3.1-8b-output'] = get_response(\"llama-3.1-8b-instant\",prompt)\n",
        "    except:\n",
        "      cf_2.append(i)\n",
        "      filtered_diff_label[i]['llama3.1-8b-output'] = 'ERROR'\n",
        "      pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mistral-Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cf_3=[]\n",
        "for i in range(0, len(filtered_diff_label)):\n",
        "    if ('mistral-large-output' not in filtered_diff_label[i] or filtered_diff_label[i]['mistral-large-output'] == 'ERROR'):\n",
        "        diff=filtered_diff_label[i]['diff']\n",
        "        prompt = f\"{diff} According to the diff, the commit message should be:\"\n",
        "        try:\n",
        "            filtered_diff_label[i]['mistral-large-output'] = getMistralResponse(prompt)\n",
        "        except:\n",
        "            cf_3.append(i)\n",
        "            filtered_diff_label[i]['mistral-large-output'] = 'ERROR'\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GPT-4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cf_4 = []\n",
        "for i in range(0, len(filtered_diff_label)):\n",
        "    if('gpt-4o-output' not in filtered_diff_label[i] or filtered_diff_label[i]['gpt-4o-output'] == 'ERROR'):\n",
        "        diff=filtered_diff_label[i]['diff']\n",
        "        prompt = f\"{diff} According to the diff, the commit message in atmost 20 words should be:\"\n",
        "        try:\n",
        "            filtered_diff_label[i]['gpt-4o-output'] = getGPTResponse(prompt)\n",
        "        except:\n",
        "            cf_4.append(i)\n",
        "            filtered_diff_label[i]['gpt-4o-output'] = 'ERROR'\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_file_name = f'Outputs/Total_Diff/diff_output_{N}.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "headers = filtered_diff_label[0].keys()\n",
        "\n",
        "with open(csv_file_name, 'w', newline='') as csv_file:\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(filtered_diff_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use Split diff for Generating Commit message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split each diff to multiple files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_diff_label=[]\n",
        "df = pd.read_csv(f'Outputs/Total_Diff/diff_output_{N}.csv')\n",
        "df_cleaned = df.replace('ERROR', pd.NA).dropna()\n",
        "filtered_diffs = list(df_cleaned['diff'])\n",
        "for i in range (0,len(filtered_diffs)):\n",
        "  result = re.split(r'(?=diff --git)', filtered_diffs[i])\n",
        "  label = filtered_labels[i]\n",
        "  for res in result:\n",
        "      if(len(res)>0):\n",
        "        new_diff_label.append({'diff':res, 'label':label, 'actual_index':i})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cf1, cf2, cf3, cf4=[],[],[],[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Llama3.1-70B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LUrIoLE3fPu"
      },
      "outputs": [],
      "source": [
        "cf1=[]\n",
        "for i in range(0, len(new_diff_label)):\n",
        "  if('llama-70b-output' not in new_diff_label[i] or new_diff_label[i]['llama-70b-output'] == 'ERROR'):\n",
        "    diff=new_diff_label[i]['diff']\n",
        "    prompt = f\"{diff} According to the diff, the commit message in atmost 20 words should be:\"\n",
        "    try:\n",
        "      new_diff_label[i]['llama-70b-output'] = get_response(\"llama-3.1-70b-versatile\",prompt)\n",
        "    except:\n",
        "      cf1.append(i)\n",
        "      new_diff_label[i]['llama-70b-output'] = 'ERROR'\n",
        "      pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Llama3.1-8B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4xiUmrPMEgQ",
        "outputId": "2ee5d916-8003-4233-f964-626304223f84"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(new_diff_label)):\n",
        "  diff=new_diff_label[i]['diff']\n",
        "  prompt = f\"{diff} According to the diff, the commit message should be:\"\n",
        "  try:\n",
        "    new_diff_label[i]['llama3.1-8b-output'] = get_response(\"llama-3.1-8b-instant\",prompt)\n",
        "  except:\n",
        "    cf2.append(i)\n",
        "    new_diff_label[i]['llama3.1-8b-output'] = 'ERROR'\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mistral-Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flag = True\n",
        "count = 10\n",
        "while(flag and count>0):\n",
        "    cf3=[]\n",
        "    for i in range (0, len(new_diff_label)):\n",
        "        if('mistral-large-output' not in new_diff_label[i] or new_diff_label[i]['mistral-large-output'] == 'ERROR'):\n",
        "            diff=new_diff_label[i]['diff']\n",
        "            prompt = f\"{diff} According to the diff, the commit message in 20 words should be:\"\n",
        "            try:\n",
        "                new_diff_label[i]['mistral-large-output'] = getMistralResponse(prompt)\n",
        "            except:\n",
        "                cf3.append(i)\n",
        "                new_diff_label[i]['mistral-large-output'] = 'ERROR'\n",
        "                pass\n",
        "    csv_file_name = f'Outputs/File_Level_Diff/split_diff_output_{N}.csv'\n",
        "    headers = new_diff_label[0].keys()\n",
        "    with open(csv_file_name, 'w', newline='') as csv_file:\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(new_diff_label)\n",
        "    print(len(cf3))\n",
        "    if(len(cf3)<=0):\n",
        "        flag=False\n",
        "    count-=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GPT-4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cf4=[]\n",
        "for i in range(0, len(new_diff_label)):\n",
        "  if('gpt-4o-output' not in new_diff_label[i] or new_diff_label[i]['gpt-4o-output'] == 'ERROR'):\n",
        "    diff=new_diff_label[i]['diff']\n",
        "    prompt = f\"{diff} According to the diff, the commit message should be:\"\n",
        "    try:\n",
        "      new_diff_label[i]['gpt-4o-output'] = getGPTResponse(prompt)\n",
        "    except:\n",
        "      cf4.append(i)\n",
        "      new_diff_label[i]['gpt-4o-output'] = 'ERROR'\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(cf4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCDveSAXA70C"
      },
      "outputs": [],
      "source": [
        "csv_file_name = f'Outputs/File_Level_Diff/split_diff_output_{N}.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_09x5YwBttT"
      },
      "outputs": [],
      "source": [
        "headers = new_diff_label[0].keys()\n",
        "\n",
        "with open(csv_file_name, 'w', newline='') as csv_file:\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(new_diff_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YD-T4Fti4wIE",
        "outputId": "de0e70fe-af74-46d6-bf91-d8a44e075163"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_file_name)\n",
        "df_cleaned = df.replace('ERROR', pd.NA).dropna()\n",
        "df_cleaned.to_csv(csv_file_name, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
